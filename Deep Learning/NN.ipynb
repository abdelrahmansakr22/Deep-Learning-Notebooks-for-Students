{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn   # nn (Neural Network) module provides layers and building blocks for deep learning models\n",
        "\n",
        "\n",
        "# Define a neural network class by inheriting from nn.Module\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        # Call the parent (nn.Module) constructor to initialize the base class\n",
        "        # This sets up internal mechanisms that allow PyTorch to track layers and parameters\n",
        "        super(SimpleNN, self).__init__()\n",
        "\n",
        "        # Define the first fully connected (linear) layer\n",
        "        # nn.Linear(input_features, output_features)\n",
        "        # Here: 2 input features â†’ 4 neurons in hidden layer\n",
        "        self.layer1 = nn.Linear(2, 4)\n",
        "\n",
        "        # Define the second fully connected (linear) layer\n",
        "        # Takes 4 features from hidden layer â†’ outputs 2 values (for 2 classes)\n",
        "        self.layer2 = nn.Linear(4, 2)\n",
        "\n",
        "\n",
        "    # Define the forward pass (how data flows through the layers)\n",
        "    def forward(self, x):\n",
        "        # Pass input x through the first layer and apply ReLU activation\n",
        "        # torch.relu() replaces negative values with 0 â†’ introduces non-linearity\n",
        "        x = torch.relu(self.layer1(x))\n",
        "\n",
        "        # Pass the activated output through the second (output) layer\n",
        "        # No activation here â†’ raw outputs (called \"logits\")\n",
        "        x = self.layer2(x)\n",
        "\n",
        "        # Return the final output\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "7KZoR5DY2N1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNN()"
      ],
      "metadata": {
        "id": "0x6lnfak2U8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create 10 random input samples, each with 2 input features\n",
        "X = torch.randn(10, 2)\n",
        "\n",
        "# Create 10 random labels (0 or 1) for classification\n",
        "y = torch.randint(0, 2, (10,))\n",
        "\n",
        "\n",
        "# Define Loss Function and Optimizer\n",
        "\n",
        "\n",
        "# Define the loss function\n",
        "# CrossEntropyLoss = Softmax + Negative Log-Likelihood\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer: Stochastic Gradient Descent (SGD)\n",
        "# model.parameters() â†’ gets all learnable weights & biases\n",
        "# lr=0.1 â†’ learning rate (controls how fast weights are updated)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "\n",
        "# Training Loop\n",
        "\n",
        "\n",
        "# Train for 50 epochs (iterations over the whole dataset)\n",
        "for epoch in range(50):\n",
        "\n",
        "    # --------------------------\n",
        "    # Forward Pass\n",
        "    # --------------------------\n",
        "    # Compute model predictions\n",
        "    outputs = model(X)\n",
        "\n",
        "    # --------------------------\n",
        "    # Compute Loss\n",
        "    # --------------------------\n",
        "    # Compare predictions with actual labels\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    # --------------------------\n",
        "    # Reset Gradients\n",
        "    # --------------------------\n",
        "    # Clear old gradients (they accumulate by default in PyTorch)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # --------------------------\n",
        "    # Backward Pass\n",
        "    # --------------------------\n",
        "    # Compute gradients (âˆ‚Loss/âˆ‚Weights)\n",
        "    loss.backward()\n",
        "\n",
        "    # --------------------------\n",
        "    # Update Weights\n",
        "    # --------------------------\n",
        "    # Adjust weights using gradients and learning rate\n",
        "    optimizer.step()\n",
        "\n",
        "    # --------------------------\n",
        "    # Print Progress\n",
        "    # --------------------------\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/50], Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "# ===============================================\n",
        "#  Inference (Testing) Mode\n",
        "# ===============================================\n",
        "\n",
        "# Switch model to evaluation mode\n",
        "# (important when using layers like Dropout or BatchNorm)\n",
        "model.eval()\n",
        "\n",
        "# Disable gradient tracking to speed up inference\n",
        "with torch.no_grad():\n",
        "\n",
        "    # Create 3 new test samples (unseen data)\n",
        "    X_test = torch.randn(3, 2)\n",
        "\n",
        "    # Run the model to get predictions (forward pass only)\n",
        "    outputs = model(X_test)\n",
        "\n",
        "    # Get the predicted class (index of max logit per row)\n",
        "    _, predicted_classes = torch.max(outputs, 1)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nðŸ§ª Inference Results\")\n",
        "    print(\"-------------------\")\n",
        "    print(\"Test Inputs:\\n\", X_test)\n",
        "    print(\"\\nRaw Model Outputs (logits):\\n\", outputs)\n",
        "    print(\"\\nPredicted Class Labels:\", predicted_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "_IkTdszD2Kfx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}